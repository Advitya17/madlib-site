<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>MADlib: k-Means Clustering (new implementation)</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script src="../mathjax/MathJax.js">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">MADlib
   &#160;<span id="projectnumber">0.4.1</span>
   </div>
   <div id="projectbrief">User Documentation</div>
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.5.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="dynsections.js"></script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div>
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
  initNavTree('group__grp__kmeans__new.html','');
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">k-Means Clustering (new implementation)</div>  </div>
<div class="ingroups"><a class="el" href="group__grp__unsuplearn.html">Unsupervised Learning</a></div></div>
<div class="contents">
<div id="dynsection-0" onclick="return toggleVisibility(this)" class="dynheader closed" style="cursor:pointer;">
  <img id="dynsection-0-trigger" src="closed.png" alt="+"/> Collaboration diagram for k-Means Clustering (new implementation):</div>
<div id="dynsection-0-summary" class="dynsummary" style="display:block;">
</div>
<div id="dynsection-0-content" class="dyncontent" style="display:none;">
<center><table><tr><td><div class="center"><iframe scrolling="no" frameborder="0" src="group__grp__kmeans__new.svg" width="515" height="40"><p><b>This browser is not able to show SVG: try Firefox, Chrome, Safari, or Opera instead.</b></p></iframe></div>
</td></tr></table></center>
</div>
<dl class="user"><dt><b>About:</b></dt><dd></dd></dl>
<p>Clustering refers to the problem of partitioning a set of objects according to some problem-dependent measure of <em>similarity</em>. In the k-means variant, one is given \( n \) points \( x_1, \dots, x_n \in \mathbb R^d \), and the goal is to position \( k \) centroids \( c_1, \dots, c_k \in \mathbb R^d \) so that the sum of <em>distances</em> between each point and its closest centroid is minimized. Each centroid represents a cluster that consists of all points to which this centroid is closest. Formally, we wish to minimize the following objective function: </p>
<p class="formulaDsp">
\[ (c_1, \dots, c_k) \mapsto \sum_{i=1}^n \min_{j=1}^k \operatorname{dist}(x_i, c_j) \]
</p>
<p> In the most common case, \( \operatorname{dist} \) is the square of the Euclidean distance.</p>
<p>This problem is computationally difficult (NP-hard), yet the local-search heuristic proposed by Lloyd [4] performs reasonably well in practice. In fact, it is so ubiquitous today that it is often referred to as the <em>standard algorithm</em> or even just the <em>k-means algorithm</em> [1]. It works as follows:</p>
<ol type="1">
<li>Seed the \( k \) centroids (see below)</li>
<li>Repeat until convergence:<ol type="a">
<li>Assign each point to its closest centroid</li>
<li>Move each centroid to a position that minimizes the sum of distances in this cluster</li>
</ol>
</li>
<li>Convergence is achieved when no points change their assignments during step 2a.</li>
</ol>
<p>Since the objective function decreases in every step, this algorithm is guaranteed to converge to a local optimum.</p>
<dl class="user"><dt><b>Implementation Notes:</b></dt><dd></dd></dl>
<p>Data points and predefined centroids (if used) are expected to be stored row-wise, in a column of type <code><a class="el" href="group__grp__svec.html">SVEC</a></code> (or any type convertible to <code><a class="el" href="group__grp__svec.html">SVEC</a></code>, like <code>FLOAT[]</code> or <code>INTEGER[]</code>). Data points with with non-finite values (NULL, NaN, infinity) in any component will be skipped during analysis.</p>
<p>The following methods are available for the centroid seeding:</p>
<ul>
<li><b>random selection</b>: Select \( k \) centroids randomly among the input points.</li>
<li><b>kmeans++</b> [2]: Start with a single centroid chosen randomly among the input points. Then iteratively choose new centroids from the input points until there is a total of \( k \) centroids. The probability for picking a particular point is proportional to its minimum distance to any existing centroid. <br/>
 Intuitively, kmeans++ favors seedings where centroids are spread out over the whole range of the input points, while at the same time not being too susceptible to outliers [2].</li>
<li><b>user-specified set of initial centroids</b>: See below for a description of the expected format of the set of initial centroids.</li>
</ul>
<p>The following distance functions can be used (computation of barycenter/mean in parentheses):</p>
<ul>
<li><b>1-norm/Manhattan</b> (element-wise mean)</li>
<li><b>2-norm/Euclidean</b> (element-wise mean)</li>
<li><b>cosine</b> (element-wise mean of normalized points)</li>
<li><b>tanimoto</b> (element-wise mean of normalized points)</li>
</ul>
<p>The algorithm stops when one of the following conditions is met:</p>
<ul>
<li>The fraction of updated points is smaller than convergence threshold (default: 0.001).</li>
<li>The algorithm reached the maximum number of allowed iterations (default: 20).</li>
</ul>
<p>A popular method to assess the quality of the clustering is the <em>silhouette coefficient</em>, a simplified version of which can be computed optionally [3]. Since for large data sets this computation is expensive, it is turned off by default (evaluate = False).</p>
<dl class="user"><dt><b>Input:</b></dt><dd>The <b>source relation</b> is expected to be of the following form (or to be implicitly convertible into the following form): <pre>{TABLE|VIEW} <em>data_points</em> (
    ...
    <em>point_id</em> BIGINT,
    <em>point_coordinates</em> FLOAT8[],
    ...
)</pre> where:<ul>
<li><em>point_id</em> is the name of an optional column with a unique ID of the data point.</li>
<li><em>point_coordinates</em> is the name of a column with point coordinates. Types such as <code>svec</code> or <code>INTEGER[]</code> are implicitly convertible to <code>FLOAT8[]</code>.</li>
</ul>
</dd></dl>
<p>If kmeans is called with a set of initial centroids, the centroid relation is expected to be of the following form: </p>
<pre>{TABLE|VIEW} <em>initial_centroids</em> (
    ...
    <em>centroid_coordinates</em> DOUBLE PRECISION[],
    ...
)</pre><p> where:</p>
<ul>
<li><em>centroid_coordinates</em> is the name of a column with coordinates</li>
</ul>
<dl class="warning"><dt><b>Warning:</b></dt><dd>This documentation needs an update!</dd></dl>
<dl class="user"><dt><b>Usage:</b></dt><dd>The k-means algorithm can be invoked in four possible ways:</dd></dl>
<ul>
<li>using <em>random</em> centroid seeding method for a provided \( k \): <pre>SELECT * FROM <a class="el" href="kmeans__new_8sql__in.html#a1e6c9981a205829baa571eca46cca1b2">kmeans_random</a>(
  '<em>src_relation</em>', '<em>src_col_data</em>', '<em>src_col_id</em>',
  '<em>out_points</em>', '<em>out_centroids</em>',
  '<em>dist_metric</em>',
  <em>max_iter</em>, <em>conv_threshold</em>,
  <em>evaluate</em>, <em>verbose</em>,
  <em>k</em>
);</pre></li>
</ul>
<ul>
<li>using <em>kmeans++</em> centroid seeding method for a provided \( k \): <pre>SELECT * FROM <a class="el" href="kmeans_8sql__in.html#aee708955d45f3c028cb595812296688f">kmeans_plusplus</a>(
  '<em>src_relation</em>', '<em>src_col_data</em>', '<em>src_col_id</em>',
  '<em>out_points</em>', '<em>out_centroids</em>',
  '<em>dist_metric</em>',
  <em>max_iter</em>, <em>conv_threshold</em>,
  <em>evaluate</em>, <em>verbose</em>,
  <em>k</em>, <em>sample_frac</em>
);</pre></li>
</ul>
<ul>
<li>with a provided centroid set: <pre>SELECT * FROM <a class="el" href="kmeans_8sql__in.html#a637ffcea6a97c3fb6607693db3899f43">kmeans_cset</a>(
  '<em>src_relation</em>', '<em>src_col_data</em>', '<em>src_col_id</em>',
  '<em>out_points</em>', '<em>out_centroids</em>',
  '<em>dist_metric</em>',
  <em>max_iter</em>, <em>conv_threshold</em>,
  <em>evaluate</em>, <em>verbose</em>,
  '<em>init_cset_rel</em>', '<em>init_cset_col</em>'
);</pre></li>
</ul>
<p>The output centroid set will be stored in the <code>out_centroids</code> table with the following structure: </p>
<pre>
 cid |  coords
-----+-------------
        ...
</pre><p>The cluster assignments for each data point will be stored in the <code>out_points</code> table with the following structure: </p>
<pre>
 pid |  coords  | cid
-----+----------+-----
         ...
</pre><dl class="user"><dt><b>Examples:</b></dt><dd></dd></dl>
<ol type="1">
<li>Prepare some input data. <div class="fragment"><pre class="fragment">sql&gt; SELECT * FROM <span class="keyword">public</span>.km_sample LIMIT 5;
          coords
--------------------------
 {1,1}:{6.76976,39.89516}
 {1,1}:{6.92655,39.54273}
 {1,1}:{6.78933,39.71434}
 {1,1}:{7.24073,39.61291}
 {1,1}:{6.72292,39.05652}
(5 rows)
</pre></div></li>
<li>Run k-means clustering using kmeans++ for centroid seeding (below example is executed in Verbose mode): <div class="fragment"><pre class="fragment">sql&gt; SELECT * FROM madlib.kmeans_plusplus(
    <span class="stringliteral">&#39;km_sample&#39;</span>, <span class="stringliteral">&#39;coords&#39;</span>, null,
    <span class="stringliteral">&#39;km_p&#39;</span>, <span class="stringliteral">&#39;km_c&#39;</span>,
    <span class="stringliteral">&#39;l2norm&#39;</span>,
    10, 0.001,
    True, True,
    10, null
);
INFO:  (<span class="stringliteral">&#39;Started k-means clustering with parameters:&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * src_relation = public.km_sample&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * src_col_data = coords&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * src_col_id = None (will be auto-generated)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * init_method = kmeans++ (sample=0.01)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * initial k = 10&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * dist_metric = l2norm&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * evaluate = True (model coefficient evaluation)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * output_points = public.km_p&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * output_centroids = public.km_c&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * verbose = True&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;Input:&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... analyzing data points&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * points: 10000 (2 dimensions), kept 10000 after removing NULLs&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... generating initial centroids&#39;</span>,)
INFO:  (<span class="stringliteral">&#39; * centroids: 10 seeded using kmeans++ (0.351 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;Execution:&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 1: updated 10000 points (0.212 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 2: updated 136 points (0.399 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 3: updated 74 points (0.2 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 4: updated 58 points (0.28 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 5: updated 66 points (0.261 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 6: updated 51 points (0.248 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 7: updated 36 points (0.257 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 8: updated 23 points (0.255 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 9: updated 21 points (0.31 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... Iteration 10: updated 13 points (0.25 sec)&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;Exit condition: reached maximum number of iterations = 10&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;Writing final output table: public.km_p...&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... 0.033 sec&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;Calculating model cost function and simplified Silhouette coefficient...&#39;</span>,)
INFO:  (<span class="stringliteral">&#39;... 0.121 sec&#39;</span>,)
-[ RECORD 1 ]-+-----------------
src_relation  | km_sample
point_count   | 10000
init_method   | <a class="code" href="kmeans__new_8sql__in.html#ab01b44e0003c3c6de2560ea7bf76fb4a" title="Perform Lloyd&#39;s k-means local-search heuristic.">kmeans</a>++
k             | 10
dist_metric   | <a class="code" href="svec_8sql__in.html#a1b6bb42a5176b020aed12734df23aca9">l2norm</a>
iterations    | 10
cost_func     | 36424.9019377
silhouette    | 0.710664950775
out_points    | km_p
out_centorids | km_c
</pre></div></li>
</ol>
<dl class="user"><dt><b>Literature:</b></dt><dd></dd></dl>
<p>[1] Wikipedia, K-means Clustering, <a href="http://en.wikipedia.org/wiki/K-means_clustering">http://en.wikipedia.org/wiki/K-means_clustering</a></p>
<p>[2] David Arthur, Sergei Vassilvitskii: k-means++: the advantages of careful seeding, Proceedings of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA'07), pp. 1027-1035, <a href="http://www.stanford.edu/~darthur/kMeansPlusPlus.pdf">http://www.stanford.edu/~darthur/kMeansPlusPlus.pdf</a></p>
<p>[3] E. R. Hruschka, L. N. C. Silva, R. J. G. B. Campello: Clustering Gene-Expression Data: A Hybrid Approach that Iterates Between k-Means and Evolutionary Search. In: Studies in Computational Intelligence - Hybrid Evolutionary Algorithms. pp. 313-335. Springer. 2007.</p>
<p>[4] Lloyd, Stuart: Least squares quantization in PCM. Technical Note, Bell Laboratories. Published much later in: IEEE Transactions on Information Theory 28(2), pp. 128-137. 1982.</p>
<dl class="see"><dt><b>See also:</b></dt><dd>File <a class="el" href="kmeans__new_8sql__in.html" title="Set of functions for k-means clustering.">kmeans_new.sql_in</a> documenting the SQL functions. </dd></dl>
</div>
</div>
  <div id="nav-path" class="navpath">
    <ul>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>


    <li class="footer">Generated on Wed Oct 31 2012 14:34:02 for MADlib by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.5.1 </li>
   </ul>
 </div>


</body>
</html>
